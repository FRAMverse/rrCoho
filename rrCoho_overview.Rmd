---
title: "rrCoho overview"
author: "Dan.Auerbach@dfw.wa.gov"
date: "`r Sys.Date()`"
params:
  file_path_escp: "copy_of_fram_coho_escapement_2022.xlsx"
  file_path_crc: "T:/DFW-Salmon Mgmt Modeling Team - General/Catch datasets/CRC/Sport Harvest Estimates 20220302.mdb"
  file_path_tocas: "T:/DFW-Salmon Mgmt Modeling Team - General/PS Coho Run Reconstruction/rrterm/tocas_coho_2000-present.csv"
editor_options: 
  chunk_output_type: console
output: 
  bookdown::html_document2:
    self_contained: true
    fig_caption: yes
    theme: flatly
    toc: yes
    toc_depth: 3
    toc_float: yes
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, results = FALSE, warning = FALSE, message = FALSE, fig.width = 9, fig.height = 9)

library("tidyverse")
library("gt")

lu <- list(
  #crc_fram = as_tibble(framr::lu_coho_crc_fram),
  crc_fram = readxl::read_excel(
     "~/OneDrive - Washington State Executive Branch Agencies/code/framr/xlsx/lu_coho.xlsx", sheet = "CRC_FRAM") |> 
     dplyr::mutate(dplyr::across(dplyr::starts_with('FisheryID'), as.integer)),
   
  #tocas_fram = as_tibble(framr::lu_coho_tocas_fram),
   tocas_fram = readxl::read_excel(
     "~/OneDrive - Washington State Executive Branch Agencies/code/framr/xlsx/lu_coho.xlsx", sheet = "TOCAS_FRAM") |> 
     dplyr::mutate(dplyr::across(dplyr::starts_with('FisheryID'), as.integer)),
   
  rmis_fram_fishery = readr::read_csv("lu_ahb_FishMap_20220826.csv") |> 
    filter(Num_Chars > 0) |> 
    select(FisheryID, FisheryName, fishery_single = Gear, Num_Chars, PSC_Code) |>
    distinct(FisheryID, FisheryName, fishery_single, Num_Chars, PSC_Code),
  
  rmis_fram_pr_mu = readr::read_csv(
    #unmodified other than field names: 'T:/DFW-Salmon Mgmt Modeling Team - General/PS Coho Run Reconstruction/rrterm/MB_Draft_2020/ReferenceFiles_4Rcode/Table1rv_RelLocName_Region_Stock_111319_Hatch.csv'
    "lu_mb_rmis_RelLoc20191113.csv"
  ) |> arrange(PR_Number, PR_MU_Number),
    
  fram_ca = readr::read_csv("lu_FRAM_CA.csv"),
  ca_pr_mu = readr::read_csv("lu_CA_PR_MU.csv")
)

data_in <- list()


dir_mb2020 <- if_else(
  grepl("apple", sessionInfo()$platform),
  "~/Washington State Executive Branch Agencies/DFW-Salmon Mgmt Modeling Team - General/PS Coho Run Reconstruction/rrterm/MB_Draft_2020",
  "T:/DFW-Salmon Mgmt Modeling Team - General/PS Coho Run Reconstruction/rrterm/MB_Draft_2020"
)

mb20 <- list()
mb20$escp <- read_csv(file.path(dir_mb2020, "Data_ProcessingSteps/Escapement_Inputs/MU_Escapement_013122.csv"))
mb20$crc <- read_csv(file.path(dir_mb2020, "Data_ProcessingSteps/Landings_Sport/RRTerm_CA_Catch_FinalInputSpt_RegularTS_012722.csv"))
mb20$tocas <- read_csv(file.path(dir_mb2020, "Data_ProcessingSteps/Landings_Commercial/RRTerm_CA_Catch_CommFinalwNames_RegularTS_121621.csv"))

#only a few years, mostly 2019-2020, as raw files
#still silly big number of columns
mb20$cwt_raw <- left_join(
  readr::read_csv(file.path(dir_mb2020, "Data_ProcessingSteps/Raw_RMIS_CWTQueryData/Recovery_Data_121621/CSV6559.csv"))
  ,
  readr::read_csv(file.path(dir_mb2020, "Data_ProcessingSteps/Raw_RMIS_CWTQueryData/Release_Data_121621/CSV6205.csv")) |> 
    select(
      tag_code = tag_code_or_release_id,
      brood_year, rearing_type,
      release_location_code, release_location_name, 
      cwt_1st_mark, cwt_1st_mark_count, 
      cwt_2nd_mark, cwt_2nd_mark_count, 
      non_cwt_1st_mark, non_cwt_1st_mark_count, 
      non_cwt_2nd_mark, non_cwt_2nd_mark_count)
  ,
  by = c("tag_code", "brood_year")
  ) #|> names()

#AllReleases
mb20$rel_all <- read_csv(file.path(dir_mb2020, "Data_ProcessingSteps/Raw_RMIS_CWTQueryData/AllRelease_Data_123021/CSV1601.csv")) |> 
  filter(brood_year > 2010)

# #Access table format, all years...
# read_csv("T:/DFW-Salmon Mgmt Modeling Team - General/PS Coho Run Reconstruction/rrterm/MB_Draft_2020/Data_ProcessingSteps/PEF_Method_Files/MU_Local_PEF_010422.csv")
mb20$pef <- read_csv(file.path(dir_mb2020, "RRTerm_Automated_DataInputs/MU_Local_PEF_010422rv.csv"))


```


https://fisheriesservices.nwifc.org/fram-model-runs/preseason-fram-model-preparation/salmon-run-reconstruction-puget-sound/

-CWT assignment is to FRAM units first
  - fishery via rec_loc_code
  - stock via ...? RMIS fields of some sort
-Fisheries sequential within PR?!? (turns out no)
-user choice to alter flagging for use of CWTs --> actually this is the "sequential" aspect, moving in from pre-terminal
  -MB codified ruleset for when to "turn-off"
-MSFs require "tricking" via small PEF (fishery-year specific based on regs) values of 0.0001
  -MB suggest improving this, perhaps via something like an MSF flag
  -this may have been the point at which 2006 Packer development stalled? Due to lack of marked-catch data 
-recall HC is copy-paste from regional Cindy Gray RR


# Established lookups

```{r read_rrterm_mdb, eval=FALSE}
db <- "T:/DFW-Salmon Mgmt Modeling Team - General/PS Coho Run Reconstruction/rrterm/CohoRR_4_CoMngrReview_wHC_013122/RRT_CO_2020-10_2022_01_31rv.mdb"

db_con <- DBI::dbConnect(drv = odbc::odbc(), .connection_string = paste0("Driver={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=", db, ";"))

rr <- list(
  lu_pr = "PR_Data", #stock "production regions"
  lu_mu = "MU_Data", #stock "management units" within production regions
  lu_ca = "CA_Data", #"catch areas"
  lu_ca_mu = "CA_MU_Table", #cross-ref
  
  pef = "MU_Local_PEF", #what makes field "Local_PEF" and where is it used?
  qval = "MU_PR_Qval", #what is field "Qvalue" and where is it used?
  hr_scaler = "MU_HR_Scaler", #what makes field "HR_Value" and where is it used?
  cwt = "CWT_Rec", #recoveries of CWTs indexed by CA and MU_Short_Name but not PR & PR_MU
  
  hvst = "CA_Catch",
  escp = "MU_Escapement",
  
  run_calc_saved = "Run_Calc_Saved" #appears to be output matching xlsx
) |> 
  map(~collect(tbl(db_con, .x)))

DBI::dbDisconnect(db_con)

```

```{r write_lu_csvs, eval=FALSE}

# #looking at missing TR portion of paired FisheryIDs
# rr$lu_ca |> filter(CA_Number == 505); lu$tocas_fram |> filter(between(FisheryID, 82, 83))
# rr$lu_ca |> filter(CA_Number == 531)
# rr$lu_ca |> filter(CA_Number == 561)
# rr$lu_ca |> filter(CA_Number == 581)
# rr$lu_ca |> filter(CA_Number == 583)
# rr$lu_ca |> filter(CA_Number == 611)
# rr$lu_ca |> filter(CA_Number == 614)
# rr$lu_ca |> filter(CA_Number == 615)
# rr$lu_ca |> filter(CA_Number == 651)
# rr$lu_ca |> filter(CA_Number == 656); lu$tocas_fram |> filter(between(FisheryID, 141, 142))
# rr$lu_ca |> filter(CA_Number == 657); lu$tocas_fram |> filter(between(FisheryID, 143, 144))
# rr$lu_ca |> filter(CA_Number == 705); lu$tocas_fram |> filter(between(FisheryID, 153, 154))
# rr$lu_ca |> filter(CA_Number == 706); lu$tocas_fram |> filter(between(FisheryID, 155, 156))
# rr$lu_ca |> filter(CA_Number == 709); lu$tocas_fram |> filter(between(FisheryID, 157, 158))
# rr$lu_ca |> filter(CA_Number == 710); lu$tocas_fram |> filter(between(FisheryID, 159, 160))
# 
# 
#mapping FRAM FisheryIDs to RRterm CA catch areas
#now added MB FW/M RRTermType field to define which FRAM timesteps used in aggregation to annual
# rr$lu_ca |>
#   bind_rows(
#     rr$lu_ca |> filter(CA_Number == 505) |> mutate(FRAM_CA_Number = 83), #A6DTr missing but catches exist
#     rr$lu_ca |> filter(CA_Number == 531) |> mutate(FRAM_CA_Number = 97), #Tr 7BCD missing but catches exist
#     rr$lu_ca |> filter(CA_Number == 561) |> mutate(FRAM_CA_Number = 102), #Tr Skag Net missing but catches exist for FRAM f102
#     rr$lu_ca |> filter(CA_Number == 581) |> mutate(FRAM_CA_Number = 110), #Tr A8A Net missing but catches exist for FRAM f110
#     rr$lu_ca |> filter(CA_Number == 583) |> mutate(FRAM_CA_Number = 112), #Tr A8D Net missing but catches exist for FRAM f112
#     rr$lu_ca |> filter(CA_Number == 611) |> mutate(FRAM_CA_Number = 120), #Tr A10 Net missing but catches exist for FRAM f120
#     rr$lu_ca |> filter(CA_Number == 614) |> mutate(FRAM_CA_Number = 122), #Tr A10A Net missing but catches exist
#     rr$lu_ca |> filter(CA_Number == 615) |> mutate(FRAM_CA_Number = 124), #Tr A10E Net missing but catches exist
#     rr$lu_ca |> filter(CA_Number == 634) |> mutate(FRAM_CA_Number = 131), #Tr A11 Net 
#     rr$lu_ca |> filter(CA_Number == 635) |> mutate(FRAM_CA_Number = 133), #Tr A11A Net 
#     rr$lu_ca |> filter(CA_Number == 651) |> mutate(FRAM_CA_Number = 138), #Tr A13 Net missing but catches exist
#     rr$lu_ca |> filter(CA_Number == 655) |> mutate(FRAM_CA_Number = 140), #Tr A13C Net 
#     rr$lu_ca |> filter(CA_Number == 656) |> mutate(FRAM_CA_Number = 142), #Tr A13A Net missing but catches exist
#     rr$lu_ca |> filter(CA_Number == 657) |> mutate(FRAM_CA_Number = 144), #Tr A13D Net missing but catches exist
#     rr$lu_ca |> filter(CA_Number == 659) |> mutate(FRAM_CA_Number = 146), #Tr A13FK Net 
#     rr$lu_ca |> filter(CA_Number == 705) |> mutate(FRAM_CA_Number = 154), #Tr 12-12B Net missing but catches exist
#     rr$lu_ca |> filter(CA_Number == 706) |> mutate(FRAM_CA_Number = 156), #Tr 9-9A Net missing but catches exist
#     rr$lu_ca |> filter(CA_Number == 709) |> mutate(FRAM_CA_Number = 158), #Tr 9-9A Net missing but catches exist
#     rr$lu_ca |> filter(CA_Number == 710) |> mutate(FRAM_CA_Number = 160) #Tr 9-9A Net missing but catches exist
#   ) |>
#   select(FisheryID = FRAM_CA_Number, CA_Number, CA_Short_Name, CWT_Flag, Cat_Flag, Type_Calc) |>
#   left_join(
#     read_csv("T:/DFW-Salmon Mgmt Modeling Team - General/PS Coho Run Reconstruction/rrterm/MB_Draft_2020/ReferenceFiles_4Rcode/Fishery_CohoFRAM_wType_101018.csv") |>
#       select(FisheryID, RRTermType),
#     by = "FisheryID"
#   ) |>
#   write_csv("lu_FRAM_CA.csv")

# #more QAQC against MB LU found later...
# #all 79 FisheryIDs have CA_Number
# lu$fram_ca |> 
#   drop_na(FisheryID) |> 
#   full_join(
#     read_csv("T:/DFW-Salmon Mgmt Modeling Team - General/PS Coho Run Reconstruction/rrterm/MB_Draft_2020/ReferenceFiles_4Rcode/FRAMFisheryID_2_RRTermCANumber.csv") #no duplicate FisheryID, |> count(FRAM_FisheryID) |> filter(n>1)
#     ,
#     by = c("FisheryID" = "FRAM_FisheryID")
#   ) |> 
#   #filter(is.na(FisheryID))
#   #count(FisheryID) |> filter(n>1)
#   #filter(is.na(CA_Number))
#   filter(!is.na(RRTerm_CA_Number)) |> 
#   filter(CA_Number != RRTerm_CA_Number)
#   print(n=200)
  

# # #mapping RRterm fishery CAs to stock PR+PR_MU
# # #the key crosswalk to assign catches to associated stocks
# # #fixing MU_Short_Name switch for Baker wild/hat
# # #wild is 2_3, hat is 2_4 in MU_data table 
# # rr$lu_mu |> filter(PR_Number==2, between(PR_MU_Number, 3, 4)) |> arrange(PR_MU_Number)
# # #but ca_pr_mu has hatchery/skgbkh to 3 and wild/skgbkw to 4 
# # rr$lu_ca_mu |> filter(PR_Number==2, between(PR_MU_Number, 3, 4)) |> arrange(PR_MU_Number)
# rr$lu_ca_mu |> 
#   mutate(
#     PR_MU = paste(PR_Number, PR_MU_Number, sep = "_"),
#     MU_Short_Name = if_else(PR_Number == 2 & PR_MU_Number == 3, "skgbkw", MU_Short_Name),
#     MU_Short_Name = if_else(PR_Number == 2 & PR_MU_Number == 4, "skgbkh", MU_Short_Name)
#     ) |>
#   write_csv("lu_CA_PR_MU.csv")


# #mapping RMIS "release_location_name" strings to RRTerm PR_MU and FRAM StockID
# #this merits revision!
# #for several reasons!!
# #used as "RelLoc_MB" in "CWT_PostProcess_StockMethod"
# full_join(
#   #RMIS release_loc to RRTerm PR/PR_MU and FRAM
#   read_csv('T:/DFW-Salmon Mgmt Modeling Team - General/PS Coho Run Reconstruction/rrterm/MB_Draft_2020/ReferenceFiles_4Rcode/Table1rv_RelLocName_Region_Stock_111319_Hatch.csv') |>
#     select(release_location_name,
#            PR_Number = RRTerm_PR,
#            PR_MU_Number = RRTerm_PR_MU,
#            StockID = FRAM_StockID,
#            FRAM_StockLongName) |>
#     mutate(PR_MU = paste(PR_Number, PR_MU_Number, sep = "_"))
#   ,
#   #using for MU_Short_Name per PR_MU
#   #various cases of duplicated MU_Short_Name per MU_Long_Name and IOFlag
#   #MB used a MU_Data[which(MU_Data$FRAM_MU_Number>0),]
#   #would prefer an approach that avoids reliance on unknown field "FRAM_MU_Number" which is not StockID
#   #but whole thing warrants revision
#   read_csv('T:/DFW-Salmon Mgmt Modeling Team - General/PS Coho Run Reconstruction/rrterm/MB_Draft_2020/ReferenceFiles_4Rcode/MU_Data_RRTermDB_072817.csv') |>
#     # #works but not completely matching MU_Short_Name strings since no way to tell which to use...
#     # distinct(PR_Number, PR_MU_Number, .keep_all = T) |> select(PR_Number, PR_MU_Number, MU_Short_Name) |>
#     drop_na(FRAM_MU_Number) |> 
#     distinct(PR_Number, PR_MU_Number, MU_Short_Name) |> 
#     mutate(PR_MU = paste(PR_Number, PR_MU_Number, sep = "_")) #|> count(PR_MU) |> filter(n>1)
#   ,
#   by = c("PR_MU", "PR_Number", "PR_MU_Number")
# ) |>
#   write_csv("lu_mb_rmis_RelLoc20191113.csv")


```

# Escapement

expects/relies on current format of *fram_coho_escapement_YEAR.xlsx* file

reads 'dataset' sheet and wrangles to 'RRTerm' summarization by PR + PR_MU

easily modified if replacement maintains comparable "view" of PR & PR_MU fields per escapement estimate value

but underlying compilation of values in 'dataset' only partially scriptable; see fram_coho_escapement_2022.R for hatchery queries etc.

```{r read_escp}
data_in$escp <- readxl::read_excel(
  path = params$file_path_escp,
  sheet = "dataset"
)|> 
  group_by(year, RRTerm_PR, RRTerm_PR_MU) |> 
  summarise(escp = sum(escp_val, na.rm = T), .groups = "drop") |> 
  mutate(
    PR_MU = paste(RRTerm_PR, RRTerm_PR_MU, sep = "_"),
    across(c(year, escp), as.integer)
    )
```

Good agreement with what appears to be MB final "RRTerm input".

  - Willapa numbers updated 2/7/22 in course of WB forecast, after MB ran 1/31/22
  - Quilcene H, Makah H, Quin H values from Carrie Cook-Tabor; also "hoodsh"? But having placeholder 0s in template ensured these were not new/NA from my file
  - Elwha was a late-changing regional conversation; need to check exactly what was agreed final with Jenni W as DA may not have all emails

```{r compare_escp}
full_join(
  data_in$escp |> filter(year == 2020),
  mb20$escp,
  by = c("RRTerm_PR" = "PR_Number", "RRTerm_PR_MU" = "PR_MU_Number")
  ) |> 
  filter(is.na(escp) | is.na(Escapement) | abs(escp - Escapement) > 1)

```

# Catches

## Recreational: CRC

```{r read_crc_coho_osx}
f <- "~/T/DFW-Salmon Mgmt Modeling Team - General/Catch datasets/CRC/Sport Harvest Estimates 20221116.mdb"
#system2("mdb-tables", args = str_replace_all(f, " ", "\\\\ "))

data_in$crc <- dplyr::left_join(
  system2("mdb-export", args = paste(str_replace_all(f, " ", "\\\\ "), "Catch"), stdout = T) |> I() |> readr::read_csv()
  ,
  system2("mdb-export", args = paste(str_replace_all(f, " ", "\\\\ "), "Area"), stdout = T) |> I() |> readr::read_csv()
  ,
  by = "AreaID") |> 
  dplyr::rename_with(.fn = tolower) |> 
  filter(species == "Coho", areacode != "192") |>
  mutate(
    area_code = str_pad(areacode, width = 2, pad = "0"),
    dplyr::across(ends_with("date"), ~as.Date(., format = "%m/%d/%y")),
    catchstatmonth = if_else(is.na(catchstatmonth), as.integer(format(catchperiodstartdate, '%m')), as.integer(catchstatmonth))
    ) |>
  group_by(area_code, areaname, year = catchyear, catchstatmonth) |> 
  summarise(catchest = sum(catchest), .groups = "drop") |> 
  mutate(
    m = factor(month.abb[catchstatmonth], levels = month.abb),
    ts = case_when(
      m %in% month.abb[1:6] ~ 1,
      m == "Jul" ~ 2,
      m == "Aug" ~ 3,
      m == "Sep" ~ 4,
      m %in% month.abb[10:12] ~ 5)
    )
```

```{r read_crc_coho}
db_con <- DBI::dbConnect(
  drv = odbc::odbc(),
  .connection_string = paste0(
    "Driver={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=",
    params$file_path_crc,
    ";"))

data_in$crc <- dplyr::left_join(
  dplyr::collect(dplyr::tbl(db_con, "Catch")) |> 
    dplyr::mutate(dplyr::across(ends_with("Date"), ~as.Date(., format = "%m/%d/%Y"))) 
  , 
  dplyr::collect(dplyr::tbl(db_con, "Area"))
  ,
  by = "AreaID") |> 
  dplyr::rename_with(.fn = tolower) |> 
  filter(species == "Coho", areacode != "192") |> 
  mutate(
    area_code = str_pad(areacode, width = 2, pad = "0"),
    #confirmed MB comment that 9 records in 2007 & 2008 were NA but all first week of Jan
    #assign from catchperiodstartdate
    catchstatmonth = if_else(is.na(catchstatmonth), as.integer(format(catchperiodstartdate, '%m')), catchstatmonth)
    ) |>
  group_by(area_code, areaname, year = catchyear, catchstatmonth) |> 
  summarise(catchest = sum(catchest), .groups = "drop") |> 
  mutate(
    m = factor(month.abb[catchstatmonth], levels = month.abb),
    ts = case_when(
      m %in% month.abb[1:6] ~ 1,
      m == "Jul" ~ 2,
      m == "Aug" ~ 3,
      m == "Sep" ~ 4,
      m %in% month.abb[10:12] ~ 5)
    )

DBI::dbDisconnect(db_con)

```

**Notes from CohoFRAM_PostSeasonwMZ_RR_SportFisheryInputs_111021.R**

Persisted removal of AreaCode == 192 and/but could/should also be handled via LU on desired CAs? `rr$lu_ca_mu`

Persisted Timestep based on `catchstatmonth` ignoring start/end dates outside single month

Persisted CRC~FRAM LU as assigned. Migrated assignment to `framr::lu_coho_crc_fram`

```{r assign_crc_fram_id}
data_in$crc <- dplyr::left_join(
  data_in$crc,
  dplyr::select(lu$crc_fram, -FisheryID_alt),
  by = "area_code")

##unassigned
#data_in$crc |> filter(is.na(FisheryID)) |> count(area_code, areaname) |> arrange(area_code) |> print(n=100)

```

Assign RRTerm CA from FRAM FisheryID

Catches only summed from FRAM timestep 3+4+5 FW or 4+5 Marine (Aug+Sep+Oct-Nov).

Seems undesirable to DA, but persisting per AHB. Apparently "dip-in" concerns.

```{r data_in_crc_ca}
#maintaining FW 3+4+5, M 4+5 per AHB, but would prefer not to exclude pre-Aug catch on basis of 'dip in' concerns
#no idea how CWT_Flag, Cat_Flag, Type_Calc are used
data_in$crc_ca <- data_in$crc |> 
  drop_na(FisheryID) |> 
  inner_join(lu$fram_ca, by = "FisheryID") |> 
  drop_na(RRTermType) |> 
  filter(ts > 2) |> 
  group_by(year, FisheryID, CA_Number, CA_Short_Name, CWT_Flag, Cat_Flag, Type_Calc, RRTermType, ts) |> 
  summarise(catchest = sum(catchest), .groups = "drop") |> 
  pivot_wider(names_from = ts, values_from = catchest, values_fill = 0) |> 
  mutate(
    catch = case_when(
      RRTermType == "FW" ~ `3` + `4` + `5`,
      RRTermType == "M" ~ `4` + `5`
    )
  )
```

Near exact agreement, differences almost certainly related to using newer CRC.

```{r compare_crc}
data_in$crc_ca |> 
  filter(year == 2020) |> 
  left_join(
    mb20$crc |> filter(Run_ID == 2020),
    by = "CA_Number"
  )

```

## Commercial: TOCAS

**Notes from CohoFRAM_PostSeason_RR_CommCatchInputs_MB121621**

>#######################################################################################
#TO QUERY RAW DATA (http://access.nwifc.org/webapps/index.asp)
#In Tribal Online Accounting System (TOCAS) interface, the query is structured as follows:
>#Biological Reports
>#TOCAS/WAFT
#Breaks: SpeciesName, Fishery, Gear, GearName, Catch Area, Disposition, Landing Date, Tribe Name.
#Select - TOCAS Filled with WAFT Data
#Values:  Select - Units
#Criteria:
# Species Selected =  
# 004 - COHO
# 044 - COHO AQUACULTURE (Note: no results, but keep in query to see if any show-up....)
# (Do not include 874 - COHO EGGS)
# Tribes Selected = ALL
# Gears Selected = ALL
# Areas Selected = ALL
# Disposition Selected = ALL
# Dealers Selected = ALL
# 
# Begin Date = 01/01/1986,  End Date = 12/31/2020  (modify as needed)
#Save the raw data in a .csv file on your computer.

Unfortunately, do not appear to actually have original raw TOCAS data: "mbellman_PostSeasCatchInputFina_12_16_2021.csv"

EDA on test version of this pretty open ended query run by Ty + Maria

```{r read_tocas}
#data_in$tocas <- read_csv(params$file_path_tocas) |> 
data_in$tocas <- read_csv("~/T/DFW-Salmon Mgmt Modeling Team - General/PS Coho Run Reconstruction/rrterm/tocas_coho_2000-present.csv") |> 
  filter(Disposition %in% c("C&SF", "COMM", "ORGN", "TEST","TKHM")) |> 
  mutate(
    landing_date = as.Date(Landing_Date, format = "%m/%d/%Y"),
    month = lubridate::month(landing_date),
    year = lubridate::year(landing_date),
    ts = case_when(
      month %in% 1:6 ~ 1,
      month == 7 ~ 2,
      month == 8 ~ 3,
      month == 9 ~ 4,
      month %in% 10:12 ~ 5)
  )

#data_in$tocas |> filter(is.na(landing_date) | is.na(month) | is.na(year))
#any(nchar(data_in$tocas$Catch_Area) < 2)
#data_in$tocas |> count(Disposition)
```

Associate to FRAM FisheryID then RRterm CA

```{r data_in_tocas_ca}
data_in$tocas_ca <- data_in$tocas |> 
  group_by(year, ts, Fishery, TribeName, Gear, Disposition, Catch_Area) |> 
  summarise(catch = sum(Units), .groups = "drop") |> 
#However, TribeName may need this soln? unique(lu_coho_tocas_fram$TribeName)
  mutate(
    TribeName = if_else(TribeName %in% c("QUINAULT - 18", "CHEHALIS - 02"), TribeName, NA_character_)
  ) |> 
  left_join(
    lu$tocas_fram |> separate_rows(Disposition) |> separate_rows(Gear) |> mutate(Gear = as.integer(Gear)),
    by = c("Fishery", "TribeName", "Gear", "Disposition", "Catch_Area")
  ) |> 
  drop_na(FisheryID) |> 
  inner_join(lu$fram_ca, by = "FisheryID") |> 
  drop_na(RRTermType) |> 
  filter(ts > 2) |> 
  #group_by(year, FisheryID, CA_Number, CA_Short_Name, CWT_Flag, Cat_Flag, Type_Calc, RRTermType, ts) |> 
  group_by(year, CA_Number, CA_Short_Name, CWT_Flag, Cat_Flag, Type_Calc, RRTermType, ts) |> 
  summarise(catch = sum(catch), .groups = "drop") |> 
  arrange(year, CA_Number, ts) |> 
  pivot_wider(names_from = ts, values_from = catch, values_fill = 0) |> 
  mutate(
    catch = case_when(
      RRTermType == "FW" ~ `3` + `4` + `5`,
      RRTermType == "M" ~ `4` + `5`
    )
  )
```

Good agreement

```{r compare_tocas}
data_in$tocas_ca |> 
  filter(year == 2020) |> 
  full_join(
    mb20$tocas |> filter(Run_ID == 2020) |> select(year = Run_ID, CA_Number, CA_Short_Name, Catch),
    by = c("year", "CA_Number")
  ) |> 
  mutate(d = catch - Catch) |> print(n=40)

```


# CWTs

Working through 2 primary MB scripts:

  - *CohoRR_CWT_PostProcess_FisheryMethod_MB121621* assigning recoveries to FRAM fisheries
  - *CohoRR_CWT_PostProcess_StockMethod_PEFCalcs_CWTForecast_MB010322_SEFMethod* assigning post-fishery wrangled recoveries to stocks and calc PEFs

## FRAM fishery assignment

MB create `clip_status` == 1 as `between(cwt_1st_mark, 5000, 6000)`
  not creating field for now, 
Drop sample_type == 5
Create rec_month from date; loses a trace number of recent records to malformed dates, could fix up
MB escapement separating out C&S, so `fishery %in% c(50:54,57:59)`, excluding RMIS 55 & 56


```{r rmis_rr_to_fram_fish}

#could filter on cwt_1st_mark and rearing_type immediately?
#see below where going between 5000:6000 and in H&M (no W or U)
#note that escapements being excluded at this stage (as they would not map to FisheryID anyway)
#can easily use Stock chunk below to map escp recoveries if needed
rmis_rr <- mb20$cwt_raw |> 
  filter(
    sample_type != 5,
    (fishery < 50 | fishery %in% 55:56 | fishery > 59)
  ) |> 
  mutate(
    rec_date = as.Date(as.character(recovery_date), format = "%Y%m%d"),
    rec_year = lubridate::year(rec_date),
    rec_month = lubridate::month(rec_date),
    ts = case_when(
      rec_month %in% 1:6 ~ 1,
      rec_month == 7 ~ 2,
      rec_month == 8 ~ 3,
      rec_month == 9 ~ 4,
      rec_month %in% 10:12 ~ 5),
    fishery_single = floor(fishery/10)
  ) |> 
  #count(run_year, rec_year) #vast majority of recovery_date years match run_year
  select(
    starts_with("rec_"), 
    ts, 
    recovery_location_code, 
    fishery, fishery_single, gear,
    estimated_number, 
    tag_code,
    brood_year, last_release_date_year,
    hatchery_location_name,
    stock_location_name,
    
    rearing_type,
    release_location_code, release_location_name, 
    cwt_1st_mark, cwt_1st_mark_count, 
    cwt_2nd_mark, cwt_2nd_mark_count, 
    non_cwt_1st_mark, non_cwt_1st_mark_count, 
    non_cwt_2nd_mark, non_cwt_2nd_mark_count
    ) |> 
  tibble::rowid_to_column("uid") 

  
#first declare temp object of only key fields
rmis_rr_to_map <- select(.data = rmis_rr, uid, recovery_location_code, fishery_single)

#now overwrite as split-then-bind pattern on Num_Chars
#per AHB request, added explicit right string padding to specified string length
#even when actual strings in RMIS and LU are/use fewer char
rmis_rr_to_map <- map_df(
  sort(unique(lu$rmis_fram_fishery$Num_Chars)),
  ~inner_join(
    rmis_rr_to_map |> 
      mutate(
        PSC_Code = str_sub(recovery_location_code, 1, .x) |> 
          str_pad(width = .x, side = "right")
        )
    ,
    lu$rmis_fram_fishery |> 
      filter(Num_Chars == .x) |> 
      mutate(
        PSC_Code = str_pad(PSC_Code, width = .x, side = "right")
        )
    ,
    by = c("PSC_Code", "fishery_single")
  )
)

#now rejoin to full dataset, after making FisheryID distinct per UID
rmis_rr <- left_join(
  rmis_rr, 
  #split out any multiple-mapped, make distinct per UID and rebind
  bind_rows(
    #records that map to a single fishery
    anti_join(
      rmis_rr_to_map
      ,
      rmis_rr_to_map |> count(uid) |> filter(n>1) |> select(uid)
      , by = "uid"
      ) |> 
      select(uid, FisheryID)
    ,
    #MAY BE 0 ROWS records that map to multiple fisheries
    semi_join(
      rmis_rr_to_map
      ,
      rmis_rr_to_map |> count(uid) |> filter(n>1) |> select(uid)
      ,
      by = "uid"
      ) |> 
      group_by(uid) |> 
      slice_max(Num_Chars, n = 1, with_ties = F) |> 
      ungroup() |> 
      select(uid, FisheryID)
  )
  ,
  by = "uid"
  )

```

```{r rmis_rr_preliminary_testing}
#unmapped recoveries
rmis_rr |> filter(is.na(FisheryID)) |> count(recovery_location_code) |> print(n=100)

#bad dates Indy (look all RMIS 2Canadian and 7other for 2018-2020 test set)
rmis_rr |> filter(is.na(rec_date)) |> count(recovery_location_code) |> print(n=100)

#removing unclipped and W tags...
rmis_rr |> 
  #count(rearing_type, cwt_1st_mark) |> 
    filter(
    between(as.integer(cwt_1st_mark), 5000, 6000),
    rearing_type %in% c("H","M")
    ) |> 
  count(rearing_type, cwt_1st_mark)


# #object 'OldRR' in StockMethod script appears to concern FRAM FisheryIDs in NT/Tr pairs
# #where a single CA_Number is associated to distinct FisheryIDs
# #now irrelevant/unnecessary given aggregation to appropriately duplicated CA_Number
# #within lu$fram_ca; see above creation chunk
# read_csv('T:/DFW-Salmon Mgmt Modeling Team - General/PS Coho Run Reconstruction/rrterm/MB_Draft_2020/ReferenceFiles_4Rcode/EditDisCAData_FramCANum_2OldRRTerm_080217.csv') |> 
#   filter(Fram_CA_Number != OldRR_FRAMCANumber) |> print(n=30)
# lu$fram_ca |> filter(FisheryID %in% 153:160) |> arrange(FisheryID)

```

## FRAM StockID assignment

Post-processed CWT recovery dataset output from: CohoRR_CWT_PostProcess_FisheryMethod_MB121621.R
 Data =  only recoveries mapped to fishery, no escapement recoveries, filtered by initial criteria 
 Remove sample_type=5 from the dataset, 
 sampled_maturity != 2, 
 rec_age >2, 
 rel_age=2 and if rel_age >2 and avg_weight <200 and study_integrity != W).

```{r rmis_rr_to_fram_pr_mu}
##massive file, not worth reading in unless essential
#read_csv("T:/DFW-Salmon Mgmt Modeling Team - General/PS Coho Run Reconstruction/rrterm/MB_Draft_2020/Data_ProcessingSteps/Fishery_Method_Files_CWT/END_MSMFisheryMapping_Match3_010322.csv")

# #basically targeting this:
# read_csv("T:/DFW-Salmon Mgmt Modeling Team - General/PS Coho Run Reconstruction/rrterm/MB_Draft_2020/RRTerm_Automated_DataInputs/CWT_Rec_4OldRRTerm_RegularTS_010422_20onlyrv.csv")
# #derived from 
# "T:/DFW-Salmon Mgmt Modeling Team - General/PS Coho Run Reconstruction/rrterm/MB_Draft_2020/Data_ProcessingSteps/Stock_Method_Files_CWT/Reg1-6AllFisheryCWTRecov_FRAMFisheryStock_010422.csv"

#add StockID and PR_MU
rmis_rr <- rmis_rr |> 
  drop_na(FisheryID, rec_date, estimated_number) |> 
  filter(
    between(as.integer(cwt_1st_mark), 5000, 6000),
    rearing_type %in% c("H","M")
    ) |>
  left_join(
    lu$rmis_fram_pr_mu,
    by = "release_location_name"
  ) |> 
  # count(StockID, PR_MU, MU_Short_Name) |> print(n=50)
  # #do not see glaringly missing release_loc from PS, a few from WA coast and ColR
  # filter(is.na(StockID)) |> count(release_location_name, release_location_code) |> arrange(desc(n)) |> print(n=60)
  drop_na(StockID, PR_MU)
```

```{r data_in_cwt}
data_in$cwt <- rmis_rr |> 
  inner_join(lu$fram_ca, by = "FisheryID") |> 
  drop_na(RRTermType) |> 
  filter(ts > 2) |> 
  group_by(
    year = rec_year, ts,
    CA_Number, CA_Short_Name, CWT_Flag, Cat_Flag, Type_Calc, RRTermType,
    PR_Number, PR_MU_Number, PR_MU, MU_Short_Name) |> 
  summarise(estimated_number = sum(estimated_number), .groups = "drop") |> 
  arrange(year, CA_Number, ts) |> 
  pivot_wider(names_from = ts, values_from = estimated_number, values_fill = 0) |> 
  mutate(
    estimated_number = case_when(
      RRTermType == "FW" ~ `3` + `4` + `5`,
      RRTermType == "M" ~ `4` + `5`
    ),
    #MB has HC fisheries as all 3+4+5
    estimated_number = if_else(
      between(CA_Number, 700, 756),
      `3` + `4` + `5`,
      estimated_number
      )
    ,`345` = `3` + `4` + `5`
  )
```

```{r comparing_rmis_rr_to_fram_pr_mu}
#reached overall OK agreement, some mismatches look related TS-included in summation

data_in$cwt |> 
  filter(year == 2020) |> 
  full_join(
    read_csv("T:/DFW-Salmon Mgmt Modeling Team - General/PS Coho Run Reconstruction/rrterm/MB_Draft_2020/RRTerm_Automated_DataInputs/CWT_Rec_4OldRRTerm_RegularTS_010422_20onlyrv.csv")
    ,
   by = c("CA_Number", "MU_Short_Name")
  ) |> 
  filter(abs(estimated_number - CWT_Est_Rec) > 1) |> 
  print(n=100)

```

## PEF calcs

Divides the total releases by the tagged and marked.

(cwt_1st/2nd_mark_count + non_cwt_1st/2nd_mark_count) / cwt_1st/2nd_mark_count

Confirmed with AHB that we want to build ratio from tagged+marked only, not including UM+tagged (as when cwt_2nd_mark==0000 and cwt_2nd_mark_count > 0)...because only examining marked recoveries (and tagged by def of being recovered).

MB calc for all releases ever, need to maintain that or okay to operate only on recovered mapped tags?

This first calcs per-tag_code total ("numerator") and marked+tagged ("denominator"), before then summing both per PR_MU to match MB code.

```{r rmis_rel_all}
##https://www.rmpc.org/files/data/RL041_ALL_FULLSET.zip
# #40mb csv, so better to just run an annual query?
# https://www.rmpc.org/files/data/RL041_ALL_FULLSET.csv

#but what exactly? all-all or all-marked or all-marked-tagged? 
#presumably all-all if getting back to tag_code eventually?

# # #reran 2010-onward all releases
# # WHERE species = '2'
# # AND   brood_year IN (2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022)
# rmis_rel_all <- readr::read_csv("https://www.rmis.org/reports/CSV1607.txt") 
# readr::write_csv(rmis_rel_all, "rmis_releases_all_coho_by2010_onward.csv")

rmis_rel_all <- readr::read_csv("rmis_releases_all_coho_by2010_onward.csv") |> 
  mutate(
    #this creates some NAs for dates of format YYYYMM, but these appear to be "!nnn..." codes for non-tagged groups except for 211071 which is totally uninformative
    last_release_date_year = lubridate::year(as.Date(as.character(last_release_date), format = "%Y%m%d"))
  ) |> 
  select(
    tag_code = tag_code_or_release_id, 
    related_group_id,
    brood_year, last_release_date_year, last_release_date,
    hatchery_location_name,
    stock_location_name,
    rearing_type,
    release_location_code, release_location_name, 
    cwt_1st_mark, cwt_1st_mark_count, 
    cwt_2nd_mark, cwt_2nd_mark_count, 
    non_cwt_1st_mark, non_cwt_1st_mark_count, 
    non_cwt_2nd_mark, non_cwt_2nd_mark_count,
    tagged_adclipped, tagged_unclipped, 
    untagged_adclipped, untagged_unclipped, untagged_unknown
    ) |> 
  tibble::rowid_to_column("uid")
```

```{r data_in_pef}
# #MB filters on rel_age==2 (constructing 'Match4' obj)
# Match2$rel_age = Match2$last_release_date_year - Match2$brood_year
# #but then groups on Run_ID (corresponding to recovery/fishing year?)
# Match4$Run_ID = (Match4$brood_year + 3)
# # but this seems like it potentially removes relevant releases?
# rmis_rel_all |> filter(tag_code == "!142017UH001")

data_in$pef <- rmis_rel_all |> 
  drop_na(last_release_date_year, release_location_name) |>
  filter(
    rearing_type %in% c("H","M"), #drop 'W', only a single 'M' in 2010onward file
    last_release_date_year - brood_year == 2
  ) |> 
  mutate(
    year = brood_year + 3,
    rel_sum = tagged_adclipped + tagged_unclipped + untagged_adclipped + untagged_unclipped + untagged_unknown,
    rel_ad = tagged_adclipped + untagged_adclipped,
    rel_adcwt = tagged_adclipped
  ) |> 
  left_join(
    lu$rmis_fram_pr_mu,
    by = "release_location_name"
  ) |> 
  drop_na(StockID, PR_MU) |> 
  group_by(year, StockID, PR_MU) |> 
  summarise(
    across(c(starts_with("rel_"), contains("agged")), sum),
    pef_ad = rel_sum / rel_ad,
    pef_adcwt = rel_sum / rel_adcwt,
    .groups = "drop"
  )

```

```{r compare_pef}
data_in$pef |> 
  filter(year==2020) |> 
  left_join(
    mb20$pef |> 
      unite("PR_MU", PR_Number, PR_MU_Number) |> 
      select(year = Run_ID, PR_MU, MU_Short_Name, Local_PEF_mdb = Local_PEF)
    ,
    by = c("year", "PR_MU")
  ) |> print(n = 50)
  
```


# Run reconstruction 

 1. combine the catch datasets, mapped to RRterm CAs from FRAM FisheryIDs via LU
 2. join the CA_PR_MU LU that defines which stock/PR_MUs are potentially assigned withn a fishery
 3. join the CWT recoveries mapped to stock-fishery (PR_MU and CA)
 4. join the PEFs per PR_MU
 5. calc the PEF*CWTestnum value (with many NAs for PR_MUs missing one or both values)
 6. join the escapement estimates

```{r}
#PR_MU 5_24 SPGSND foxicc has no compiled escapement and is excluded by inner_join
#as is any other unit with no escapement in current escapement compilation
#could certainly drop_na(HR_Flag) now rather than later
#same for filter PR_Number 1-6
escp_hvst_cwt_pef <- full_join(
  lu$ca_pr_mu #|> drop_na(HR_Flag) |> filter(PR_Number < 7)
  ,
  data_in$escp |> select(year, PR_MU, escp) |> 
    filter(year == 2020)
  ,
  by = "PR_MU"
  ) |>
  #add catches
#!!Will want to have dropped CWT_Flag from lu_FRAM_CA.csv
#!!but leaving for now to allow checks of 2020
  left_join(
    bind_rows(
      data_in$crc_ca |> select(year, CA_Number:RRTermType, catch)
      ,
      data_in$tocas_ca |> select(year, CA_Number:RRTermType, catch)
      ) |> 
      select(year, CA_Number, 
             CWT_Flag, #Cat_Flag, Type_Calc,
             RRTermType, catch)
    ,
    by = c("year", "CA_Number")
  ) |> 
  #join CWT estimated number values
  left_join(
    data_in$cwt |> 
      select(year, CA_Number, PR_MU, est_num = estimated_number)
    ,
    by = c("year", "CA_Number", "PR_MU")
  ) |> 
  #join PEFs
  left_join(
    data_in$pef |> 
      select(year, PR_MU, pef_adcwt)
    ,
    by = c("year", "PR_MU")
  ) |> 
  mutate(
    cwt_pef = est_num * pef_adcwt
  ) |>
  arrange(year, CA_Number, PR_Number, PR_MU_Number)
  

# #recoveries of PR_MUs that are excluded from CAs with HR_Flag==1 
# escp_hvst_cwt_pef |> 
#   #drop_na(HR_Flag)
#   filter(!is.na(est_num)) |> 
#   filter(is.na(HR_Flag)) |> 
#   print(n=100)

```

```{r}
escp_hvst_cwt_pef |> 
  filter(
    HR_Flag == 1,
    PR_Number < 7
    ) |> 
  split(~PR_Number)

```




OLDER

```{r initiate_hvst_cwt_pef_escp}
hvst_cwt_pef_escp <- bind_rows(
  data_in$crc_ca |> select(year, CA_Number:RRTermType, catch)
  ,
  data_in$tocas_ca |> select(year, CA_Number:RRTermType, catch)
) |> 
  filter(year == 2020) |> 
  #join potential PR_MUs within CAs
  left_join(lu$ca_pr_mu |> select(-CA_Short_Name), by = "CA_Number") |> 
# #could do here but maybe need to allow PR_MUs that have CWTs?
#   drop_na(HR_Flag)
  #join CWT estimated number values
  left_join(
    data_in$cwt |> 
      select(year, CA_Number, PR_MU, est_num = estimated_number)
    ,
    by = c("year", "CA_Number", "PR_MU")
  ) |> 
  #join PEFs
  left_join(
    data_in$pef |> 
      select(year, PR_MU, pef_adcwt)
    ,
    by = c("year", "PR_MU")
  ) |> 
  mutate(
    cwt_pef = est_num * pef_adcwt
  ) |>
  #join escapement estimates
  left_join(
    data_in$escp |> 
      select(year, PR_MU, escp)
    ,
    by = c("year", "PR_MU")
  ) |> 
  arrange(year, CA_Number, PR_Number, PR_MU_Number)

# hvst_cwt_pef_escp |> filter(!is.na(cwt_pef)) |> print(n=100)
```
 
12/27/22 call with AHB

 - confirmed HR_Flag == 1, stock is affected/included in fishery
 - but need to reconceptualize around "per-PR", found that fishery/CA calcs are sequential
  with CA_Number defining order, largest-first to smallest-last
  e.g. Skagit example with Skagit R sport based entirely on escp, then 8-1spt on escp+SkgRspt, etc. through net

So, may not need to actually `split` but atleast a `group_by` on *PR_Number* 

```{r}
hvst_cwt_pef_escp |> 
  filter(HR_Flag == 1 | cwt_pef > 0) |> 
  split(~PR_Number)
```

 7. calculate per year-CA the CWT*PEF-affected portion of the catch
 8. deduct that CWT-PEFcatch where it exists
 9. 

```{r revised_flow}
hvst_cwt_pef_escp |> 
  #back join total CWT*PEF across MUs per CA
  left_join(
    hvst_cwt_pef_escp |> 
      filter(CWT_Flag == 1) |> 
      group_by(year, CA_Number) |> 
      summarise(
        cwt_pef_sum = sum(cwt_pef, na.rm = T),
        .groups = "drop"
        )
    , 
    by = c("year", "CA_Number")
    ) |>
  #deduct expanded CWT catch if exists
  mutate(
    catch_cwt_pef_sum = if_else(
      is.na(cwt_pef_sum), 
      catch, 
      catch - cwt_pef_sum
      )
  ) |>
#NEXT FINISH FROM HERE

  #assign remainder by relative escapement abundance
  group_by(year, CA_Number) |> 
  mutate(
    escp = if_else(is.na(HR_Flag), 0, escp), #stocks not affected by rule
    escp = if_else(!is.na(CWT_Flag) & CWT_Flag == 1, 0, escp),
    
    pr_mu_pct = escp / sum(escp, na.rm = T),
    catch_pct = catch_cwt_pef_sum * pr_mu_pct,
    catch_final = if_else(
      !is.na(Flag_cwt) & Flag_cwt == 1,
      cwt_pef,
      catch_pct
      )
    ) |> 
  ungroup() 

```


